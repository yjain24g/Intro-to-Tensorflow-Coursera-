{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Course 2 week 3.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"gwPmJGd6ykZ-"},"source":["# Import all the necessary files!\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from os import getcwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8btt9hEzGkB"},"source":["path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n","\n","# Import the inception model  \n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","# Create an instance of the inception model from the local pre-trained weights\n","local_weights_file = path_inception\n","\n","pre_trained_model = InceptionV3(\n","    input_shape=(150, 150, 3),\n","    include_top=False,\n","    weights=None\n",")\n","pre_trained_model.load_weights(local_weights_file)\n","\n","# Make all the layers in the pre-trained model non-trainable\n","for layer in pre_trained_model.layers:\n","    layer.trainable = False\n","  \n","# Print the model summary\n","pre_trained_model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCCFNPBnzJRa"},"source":["last_layer = pre_trained_model.get_layer('mixed7')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8_b52KHzNLI"},"source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('acc')>0.97):\n","      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n","      self.model.stop_training = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJj9v4hyzXmF"},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(.2)(x)                  \n","# Add a final sigmoid layer for classification\n","x = layers.Dense  (1, activation='sigmoid')(x)           \n","\n","model = Model(pre_trained_model.input, x) \n","\n","model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'binary_crossentropy', \n","              metrics = ['accuracy']\n","             )\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NAxj6RkzYQK"},"source":["path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n","# Get the Horse or Human Validation dataset\n","path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import os\n","import zipfile\n","import shutil\n","\n","shutil.rmtree('/tmp')\n","local_zip = path_horse_or_human\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/training')\n","zip_ref.close()\n","\n","local_zip = path_validation_horse_or_human\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/validation')\n","zip_ref.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5TVYRnmzuch"},"source":["train_dir = '/tmp/training'\n","validation_dir = '/tmp/validation'\n","\n","train_horses_dir = os.path.join(train_dir, 'horses') \n","train_humans_dir = os.path.join(train_dir, 'humans') \n","validation_horses_dir = os.path.join(validation_dir, 'horses')\n","validation_humans_dir = os.path.join(validation_dir, 'humans')\n","\n","train_horses_fnames = os.listdir(train_horses_dir)\n","train_humans_fnames = os.listdir(train_humans_dir)\n","validation_horses_fnames = os.listdir(validation_horses_dir)\n","validation_humans_fnames = os.listdir(validation_humans_dir)\n","\n","print(len(train_horses_fnames))\n","print(len(train_humans_fnames))\n","print(len(validation_horses_fnames))\n","print(len(validation_humans_fnames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-ApVjk4zxEw"},"source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255.,\n","    rotation_range = 40,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True\n",")\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator(\n","    rescale = 1./255.\n",")\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    batch_size=10,\n","    class_mode='binary',\n","    target_size=(150,150)\n",")     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  test_datagen.flow_from_directory(\n","    validation_dir,\n","    batch_size=10,\n","    class_mode='binary',\n","    target_size=(150,150)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYjz_ruQz9Vm"},"source":["callbacks = myCallback()\n","history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=10,  \n","      epochs=3,\n","      verbose=1,\n","      validation_data = validation_generator,\n","      validation_steps=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y44ac61Wz-Av"},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend(loc=0)\n","plt.figure()\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}
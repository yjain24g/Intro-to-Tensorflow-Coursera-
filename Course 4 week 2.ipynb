{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Course 4 week 2.ipynb","provenance":[],"authorship_tag":"ABX9TyNxkYPEeoi0F9aorLm7g9JM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Uwx2jjktv-IP"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MGiFGPPwDkx"},"source":["def plot_series(time, series, format=\"-\", start=0, end=None):\n","    plt.plot(time[start:end], series[start:end], format)\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Value\")\n","    plt.grid(False)\n","\n","def trend(time, slope=0):\n","    return slope * time\n","\n","def seasonal_pattern(season_time):\n","    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n","    return np.where(season_time < 0.1,\n","                    np.cos(season_time * 6 * np.pi), a\n","                    2 / np.exp(9 * season_time))\n","  def seasonality(time, period, amplitude=1, phase=0):\n","    \"\"\"Repeats the same pattern at each period\"\"\"\n","    season_time = ((time + phase) % period) / period\n","    return amplitude * seasonal_pattern(season_time)\n","\n","def noise(time, noise_level=1, seed=None):\n","    rnd = np.random.RandomState(seed)\n","    return rnd.randn(len(time)) * noise_level\n","\n","time = np.arange(10 * 365 + 1, dtype=\"float32\")\n","baseline = 10 # YOUR CODE HERE #\n","series = trend(time, 0.1)   # YOUR CODE HERE #\n","baseline = 10\n","amplitude = 40\n","slope = 0.005 # YOUR CODE HERE #\n","noise_level = 3 # YOUR CODE HERE #\n","\n","# Create the series\n","series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n","# Update with noise\n","series += noise(time, noise_level, seed=51)\n","\n","split_time = 3000\n","time_train = time[:split_time]\n","x_train = series[:split_time]\n","time_valid = time[split_time:]\n","x_valid = series[split_time:]\n","\n","window_size = 20\n","batch_size = 32\n","shuffle_buffer_size = 1000\n","\n","plot_series(time, series)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sCP0VI-wKFT"},"source":["def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","  dataset = tf.data.Dataset.from_tensor_slices(series)\n","  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n","  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n","  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n","  dataset = dataset.batch(batch_size).prefetch(1)\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCsIOGnhwK1E"},"source":["dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n","\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(100, input_shape=[window_size], activation=\"relu\"), \n","    tf.keras.layers.Dense(10, activation=\"relu\"), \n","    tf.keras.layers.Dense(1)\n","])\n","\n","lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n","    lambda epoch: 1e-8 * 10**(epoch / 20))\n","optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n","model.compile(loss=\"mse\", optimizer=optimizer)\n","history = model.fit(dataset, epochs=100, callbacks=[lr_schedule], verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XnRZD1I7w2MT"},"source":["lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n","plt.semilogx(lrs, history.history[\"loss\"])\n","plt.axis([1e-8, 1e-3, 0, 300])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jiVWNxMw8Rs"},"source":["window_size = 30\n","dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n","\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n","  tf.keras.layers.Dense(10, activation=\"relu\"),\n","  tf.keras.layers.Dense(1)\n","])\n","\n","optimizer = tf.keras.optimizers.SGD(lr=8e-6, momentum=0.9)\n","model.compile(loss=\"mse\", optimizer=optimizer)\n","history = model.fit(dataset, epochs=500, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7f1q6nMw_ZU"},"source":["loss = history.history['loss']\n","epochs = range(len(loss))\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPAgargnwS1J"},"source":["forecast = []\n","for time in range(len(series) - window_size):\n","  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n","\n","forecast = forecast[split_time-window_size:]\n","results = np.array(forecast)[:, 0, 0]\n","\n","\n","plt.figure(figsize=(10, 6))\n","\n","plot_series(time_valid, x_valid)\n","plot_series(time_valid, results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtROm9UewZ_w"},"source":["tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"],"execution_count":null,"outputs":[]}]}